{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q1oFbIUnS9xW"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18615,
     "status": "ok",
     "timestamp": 1669356566301,
     "user": {
      "displayName": "陳皇佑",
      "userId": "01619903051591522740"
     },
     "user_tz": -480
    },
    "id": "efvT7v9RjPRX",
    "outputId": "ad48f8a4-9c36-4168-cc80-c3fff7e0dd0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZUuypNKln6b2"
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('/content/drive/MyDrive/DMLab2/data/train_data_colab.csv')\n",
    "df_test  = pd.read_csv('/content/drive/MyDrive/DMLab2/data/test_data_colab.csv')\n",
    "label_trans=['anger', 'anticipation', 'disgust', 'fear', 'sadness', 'surprise', 'trust', 'joy']\n",
    "raw_train_x, raw_train_y = list(df_train['text']), list(df_train['emotion'])\n",
    "raw_test_x = list(df_test['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 555,
     "status": "ok",
     "timestamp": 1669356577084,
     "user": {
      "displayName": "陳皇佑",
      "userId": "01619903051591522740"
     },
     "user_tz": -480
    },
    "id": "OJ5-9sQNhaup",
    "outputId": "c638b34a-7e0e-4218-de47-f0c32f2e2512"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['anger', 'anticipation', 'disgust', 'fear', 'joy', 'sadness',\n",
       "       'surprise', 'trust'], dtype='<U12')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(raw_train_y)\n",
    "label_encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 613,
     "status": "ok",
     "timestamp": 1669356577694,
     "user": {
      "displayName": "陳皇佑",
      "userId": "01619903051591522740"
     },
     "user_tz": -480
    },
    "id": "PoPCJ9uLh7Bx",
    "outputId": "c1a4c95a-5cbb-406a-f203-a14093fc3501"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 1., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "def label_encode(le, labels):\n",
    "    enc = le.transform(labels)\n",
    "    return to_categorical(enc)\n",
    "\n",
    "def label_decode(le, one_hot_label):\n",
    "    dec = np.argmax(one_hot_label, axis=1)\n",
    "    return le.inverse_transform(dec)\n",
    "\n",
    "raw_train_y = label_encode(label_encoder, raw_train_y)\n",
    "raw_train_y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1669356577694,
     "user": {
      "displayName": "陳皇佑",
      "userId": "01619903051591522740"
     },
     "user_tz": -480
    },
    "id": "uzekq-LvlfXw",
    "outputId": "bea11acd-e4fd-4b48-a2d4-75ddb65acd13"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_train_y[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GAdWX-QEilf9"
   },
   "outputs": [],
   "source": [
    "train_x, val_x, train_y, val_y = train_test_split(raw_train_x, raw_train_y, test_size=0.2, random_state=1)\n",
    "\n",
    "# df_train = pd.DataFrame({'text': train_x, 'anger':train_y[:][0], 'anticipation':train_y[:][1], 'disgust':train_y[:][2],\\\n",
    "#                          'fear':train_y[:][3], 'joy':train_y[:][4], 'sadness':train_y[:][5],'surprise':train_y[:][6], 'trust':train_y[:][7]})\n",
    "# df_val = pd.DataFrame({'text': val_x,  'anger':val_y[0], 'anticipation':val_y[1], 'disgust':val_y[2],\\\n",
    "#                          'fear':val_y[3], 'joy':val_y[4], 'sadness':val_y[5],'surprise':val_y[6], 'trust':val_y[7]})\n",
    "\n",
    "# df_train.to_csv('/content/drive/MyDrive/MLFinal/MLFinalData/train_set.csv')\n",
    "# df_val.to_csv('/content/drive/MyDrive/MLFinal/MLFinalData/val_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 219
    },
    "executionInfo": {
     "elapsed": 731,
     "status": "error",
     "timestamp": 1669356579511,
     "user": {
      "displayName": "陳皇佑",
      "userId": "01619903051591522740"
     },
     "user_tz": -480
    },
    "id": "LNgpH3HRe3dv",
    "outputId": "20038cc0-4c70-4fef-fac4-0a058f67e1f6"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-e07aeff55153>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m# test_str = HE_RE.sub('', test_str)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0mremove_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;31m# test_str\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'remove_tags' is not defined"
     ]
    }
   ],
   "source": [
    "AM_RE = re.compile(r'am',re.I)\n",
    "IS_RE = re.compile(r'is',re.I)\n",
    "ARE_RE = re.compile(r'are',re.I)\n",
    "AT_RE = re.compile(r'at',re.I)\n",
    "IN_RE = re.compile(r'in',re.I)\n",
    "ON_RE = re.compile(r'on',re.I)\n",
    "THE_RE = re.compile(r'the',re.I)\n",
    "SHE_RE = re.compile(r'she',re.I)\n",
    "THEY_RE = re.compile(r'they',re.I)\n",
    "MY_RE = re.compile(r'my',re.I)\n",
    "HER_RE = re.compile(r'her',re.I)\n",
    "HIS_RE = re.compile(r'his',re.I)\n",
    "OUR_RE = re.compile(r'our',re.I)\n",
    "THEIR_RE = re.compile(r'their',re.I)\n",
    "WE_RE = re.compile(r'we',re.I)\n",
    "HE_RE = re.compile(r'he',re.I)\n",
    "\n",
    "\n",
    "test_str = 'He is the man who are happy in the home. I am glad she Are on table at school.<LH>'\n",
    "# test_str = AM_RE.sub('', test_str) \n",
    "# test_str = IS_RE.sub('', test_str) \n",
    "# test_str = ARE_RE.sub('', test_str)  \n",
    "# test_str = AT_RE.sub('', test_str)  \n",
    "# test_str = IN_RE.sub('', test_str)  \n",
    "# test_str = ON_RE.sub('', test_str)  \n",
    "# test_str = THEY_RE.sub('', test_str)\n",
    "# test_str = SHE_RE.sub('', test_str)\n",
    "# test_str = THEIR_RE.sub('', test_str)\n",
    "# test_str = HER_RE.sub('', test_str)\n",
    "# test_str = HIS_RE.sub('', test_str)\n",
    "# test_str = OUR_RE.sub('', test_str)\n",
    "# test_str = WE_RE.sub('', test_str)\n",
    "# test_str = THE_RE.sub('', test_str)\n",
    "# test_str = HE_RE.sub('', test_str)\n",
    "\n",
    "remove_tags(test_str)\n",
    "# test_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_zq_e5LY5v1b"
   },
   "outputs": [],
   "source": [
    "TAG_RE = re.compile(r'<[^>]+>')\n",
    "\n",
    "AM_RE = re.compile(r'\\s+am\\s+',re.I)\n",
    "IS_RE = re.compile(r'\\s+is\\s+',re.I)\n",
    "ARE_RE = re.compile(r'\\s+are\\s+',re.I)\n",
    "AT_RE = re.compile(r'\\s+at\\s+',re.I)\n",
    "IN_RE = re.compile(r'\\s+in\\s+',re.I)\n",
    "ON_RE = re.compile(r'\\s+on\\s+',re.I)\n",
    "THE_RE = re.compile(r'\\s+the\\s+',re.I)\n",
    "SHE_RE = re.compile(r'\\s+she\\s+',re.I)\n",
    "THEY_RE = re.compile(r'\\s+they\\s+',re.I)\n",
    "MY_RE = re.compile(r'\\s+my\\s+',re.I)\n",
    "HER_RE = re.compile(r'\\s+her\\s+',re.I)\n",
    "HIS_RE = re.compile(r'\\s+his\\s+',re.I)\n",
    "OUR_RE = re.compile(r'\\s+our\\s+',re.I)\n",
    "THEIR_RE = re.compile(r'\\s+their\\s+',re.I)\n",
    "WE_RE = re.compile(r'\\s+we\\s+',re.I)\n",
    "HE_RE = re.compile(r'\\s+he\\s+',re.I)\n",
    "IT_RE = re.compile(r'\\s+it\\s+',re.I)\n",
    "\n",
    "def remove_tags(text):\n",
    "    return TAG_RE.sub('', text)\n",
    "\n",
    "def remove_unused(test_str):\n",
    "    test_str = AM_RE.sub(' ', test_str) \n",
    "    test_str = IS_RE.sub(' ', test_str) \n",
    "    test_str = ARE_RE.sub(' ', test_str)  \n",
    "    test_str = AT_RE.sub(' ', test_str)  \n",
    "    test_str = IN_RE.sub(' ', test_str)  \n",
    "    test_str = ON_RE.sub(' ', test_str)  \n",
    "    test_str = THEY_RE.sub(' ', test_str)\n",
    "    test_str = SHE_RE.sub(' ', test_str)\n",
    "    test_str = THEIR_RE.sub(' ', test_str)\n",
    "    test_str = HER_RE.sub(' ', test_str)\n",
    "    test_str = HIS_RE.sub(' ', test_str)\n",
    "    test_str = OUR_RE.sub(' ', test_str)\n",
    "    test_str = WE_RE.sub(' ', test_str)\n",
    "    test_str = THE_RE.sub(' ', test_str)\n",
    "    test_str = HE_RE.sub(' ', test_str)\n",
    "    test_str = IT_RE.sub(' ', test_str)\n",
    "    return test_str\n",
    "\n",
    "def preprocess_text(sen):\n",
    "    # Removing html tags\n",
    "    sentence = remove_tags(sen)\n",
    "\n",
    "\n",
    "    # Remove punctuations and numbers\n",
    "    sentence = re.sub('[^a-zA-Z]', ' ', sentence)\n",
    "\n",
    "    # Single character removal\n",
    "    sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence)\n",
    "\n",
    "    # sentence = remove_unused(sentence)\n",
    "\n",
    "    # Removing multiple spaces\n",
    "    sentence = re.sub(r'\\s+', ' ', sentence)\n",
    "\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j5fcFcNa5wW0"
   },
   "outputs": [],
   "source": [
    "X_train = []\n",
    "sentences = train_x\n",
    "for sen in sentences:\n",
    "    X_train.append(preprocess_text(sen))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4XipJCATRrQs"
   },
   "outputs": [],
   "source": [
    "train_x[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j52zTFFGqTLM"
   },
   "outputs": [],
   "source": [
    "X_train[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KpHcfA3tz_RW"
   },
   "outputs": [],
   "source": [
    "X_val = []\n",
    "sentences = val_x\n",
    "for sen in sentences:\n",
    "    X_val.append(preprocess_text(sen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TjkUx_eFo8ei"
   },
   "outputs": [],
   "source": [
    "y_train = train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bS-LMmAJ0usv"
   },
   "outputs": [],
   "source": [
    "y_val = val_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "08R-f1XWZYWh"
   },
   "outputs": [],
   "source": [
    "X_test = []\n",
    "sentences = raw_test_x\n",
    "for sen in sentences:\n",
    "    X_test.append(preprocess_text(sen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QBTn9uTg54mN"
   },
   "outputs": [],
   "source": [
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=10000)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_val = tokenizer.texts_to_sequences(X_val)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "max_len = 15\n",
    "# padding sentences to the same length\n",
    "X_train = tf.keras.preprocessing.sequence.pad_sequences(X_train, padding='post', maxlen=max_len)\n",
    "X_val = tf.keras.preprocessing.sequence.pad_sequences(X_val, padding='post', maxlen=max_len)\n",
    "X_test = tf.keras.preprocessing.sequence.pad_sequences(X_test, padding='post', maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FVBBjuuhNKB8"
   },
   "outputs": [],
   "source": [
    "# show the preprocessed data\n",
    "len(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6080,
     "status": "ok",
     "timestamp": 1669356709992,
     "user": {
      "displayName": "陳皇佑",
      "userId": "01619903051591522740"
     },
     "user_tz": -480
    },
    "id": "IQ6uEtu6582v",
    "outputId": "07a4374a-7f5b-4872-9cf5-11bc8bb7ce8f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([64, 15]), TensorShape([64, 8]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BUFFER_SIZE = len(X_train)\n",
    "BATCH_SIZE = 64\n",
    "steps_per_epoch = len(X_train)//BATCH_SIZE\n",
    "embedding_dim = 256\n",
    "units = 1024\n",
    "# only reserve 10000 words\n",
    "vocab_size = 10000\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "# test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
    "# test_dataset = test_dataset.batch(BATCH_SIZE, drop_remainder=False)\n",
    "\n",
    "example_input_batch, example_target_batch = next(iter(dataset))\n",
    "example_input_batch.shape, example_target_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7acrGmwK0mi-"
   },
   "outputs": [],
   "source": [
    "val_dataset = tf.data.Dataset.from_tensor_slices((X_val, y_val))\n",
    "val_dataset = val_dataset.batch(BATCH_SIZE, drop_remainder=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1669362326551,
     "user": {
      "displayName": "陳皇佑",
      "userId": "01619903051591522740"
     },
     "user_tz": -480
    },
    "id": "MbfJJt-Qv3hQ",
    "outputId": "5c32f903-7bcc-48cc-8045-48a3162f57cb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset element_spec=(TensorSpec(shape=(None, 15), dtype=tf.int32, name=None), TensorSpec(shape=(None, 8), dtype=tf.float32, name=None))>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EtizrPDIKUUp"
   },
   "source": [
    "# Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gdfFw6t36Ae3"
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "        # vacab_size=10000, embedding_dim=256 enc_units=1024 batch_sz=64\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.enc_units = enc_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(self.enc_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_activation='sigmoid',\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "\n",
    "    def call(self, x, hidden):\n",
    "        # x is the training data with shape == (batch_size，max_length)  -> (64, 100)\n",
    "        # which means there are batch_size sentences in one batch, the length of each sentence is max_length\n",
    "        # hidden state shape == (batch_size, units) -> (64, 1024)\n",
    "        # after embedding, x shape == (batch_size, max_length, embedding_dim) -> (64, 100, 256)\n",
    "        x = self.embedding(x)\n",
    "        \n",
    "        # output contains the state(in GRU, the hidden state and the output are same) from all timestamps,\n",
    "        # output shape == (batch_size, max_length, units) -> (64, 100, 1024)\n",
    "        # state is the hidden state of the last timestamp, shape == (batch_size, units) -> (64, 1024)\n",
    "        output, state = self.gru(x, initial_state=hidden)\n",
    "        \n",
    "        return output, state\n",
    "\n",
    "    def initialize_hidden_state(self):\n",
    "        # initialize the first state of the gru,  shape == (batch_size, units) -> (64, 1024)\n",
    "        return tf.zeros((self.batch_sz, self.enc_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2010,
     "status": "ok",
     "timestamp": 1669356711978,
     "user": {
      "displayName": "陳皇佑",
      "userId": "01619903051591522740"
     },
     "user_tz": -480
    },
    "id": "s_QiTj9q6D62",
    "outputId": "a2a1b7f9-4a27-4578-cf8a-8345b45c398e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder output shape: (batch size, sequence length, units) (64, 15, 1024)\n",
      "Encoder Hidden state shape: (batch size, units) (64, 1024)\n",
      "tf.Tensor([ True  True  True ...  True  True  True], shape=(1024,), dtype=bool)\n"
     ]
    }
   ],
   "source": [
    "encoder = Encoder(vocab_size, embedding_dim, units, BATCH_SIZE)\n",
    "\n",
    "# sample input\n",
    "sample_hidden = encoder.initialize_hidden_state()\n",
    "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
    "print('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
    "print('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))\n",
    "# the output and the hidden state of GRU is equal\n",
    "print(sample_output[-1, -1, :] == sample_hidden[-1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zda9EZU96Fox"
   },
   "outputs": [],
   "source": [
    "class LuongAttention(tf.keras.Model):\n",
    "    # def __init__(self, units):\n",
    "    #     super(LuongAttention, self).__init__()\n",
    "    #     # TODO: Complete the function.\n",
    "    #     pass\n",
    "\n",
    "    # def call(self, query, values):\n",
    "    #     # TODO: Implement the Luong attention.\n",
    "    #     pass\n",
    "\n",
    "    def __init__(self, units):\n",
    "        super(LuongAttention, self).__init__()\n",
    "        self.W = tf.keras.layers.Dense(units)\n",
    "\n",
    "    def call(self, query, values):\n",
    "        # query shape == (batch_size, hidden size)\n",
    "        # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n",
    "        # we are doing this to perform addition to calculate the score\n",
    "        hidden_with_time_axis = tf.expand_dims(query, 1)\n",
    "\n",
    "        # score shape == (batch_size, max_length, 1)\n",
    "        score = tf.linalg.matmul(self.W(values), hidden_with_time_axis, transpose_b=True)\n",
    "\n",
    "        # attention_weights shape == (batch_size, max_length, 1)\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "\n",
    "        # context_vector shape == (batch_size, max_length, hidden_size)\n",
    "        context_vector = attention_weights * values\n",
    "        \n",
    "        # context_vector shape after sum == (batch_size, hidden_size)\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "        return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6s5QIjHLJ1oW"
   },
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.Model):\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, query, values):\n",
    "        # query shape == (batch_size, hidden size)\n",
    "        # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n",
    "        # we are doing this to perform addition to calculate the score\n",
    "        hidden_with_time_axis = tf.expand_dims(query, 1)\n",
    "\n",
    "        # score shape == (batch_size, max_length, 1)\n",
    "        # we get 1 at the last axis because we are applying score to self.V\n",
    "        # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
    "        score = self.V(tf.nn.tanh(self.W1(values) + self.W2(hidden_with_time_axis)))\n",
    "\n",
    "        # attention_weights shape == (batch_size, max_length, 1)\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "\n",
    "        # context_vector shape == (batch_size, max_length, hidden_size)\n",
    "        context_vector = attention_weights * values\n",
    "        \n",
    "        # context_vector shape after sum == (batch_size, hidden_size)\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "        return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P0K-m4N2Reh5"
   },
   "outputs": [],
   "source": [
    "class DotAttention(tf.keras.Model):\n",
    "    # def __init__(self, units):\n",
    "    #     super(LuongAttention, self).__init__()\n",
    "    #     # TODO: Complete the function.\n",
    "    #     pass\n",
    "\n",
    "    # def call(self, query, values):\n",
    "    #     # TODO: Implement the Luong attention.\n",
    "    #     pass\n",
    "\n",
    "    def __init__(self, units):\n",
    "        super(DotAttention, self).__init__()\n",
    "\n",
    "    def call(self, query, values):\n",
    "        # query shape == (batch_size, hidden size)\n",
    "        # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n",
    "        # we are doing this to perform addition to calculate the score\n",
    "        hidden_with_time_axis = tf.expand_dims(query, 1)\n",
    "\n",
    "        # score shape == (batch_size, max_length, 1)\n",
    "        score = tf.linalg.matmul(values, hidden_with_time_axis, transpose_b=True)\n",
    "\n",
    "        # attention_weights shape == (batch_size, max_length, 1)\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "\n",
    "        # context_vector shape == (batch_size, max_length, hidden_size)\n",
    "        context_vector = attention_weights * values\n",
    "        \n",
    "        # context_vector shape after sum == (batch_size, hidden_size)\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "        return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hOTr2_Hh6HV_"
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, dec_units, batch_sz):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.dec_units = dec_units\n",
    "        \n",
    "        # pass through four fully connected layers, the model will return \n",
    "        # the probability of the positivity of the sentence\n",
    "        self.fc_1 = tf.keras.layers.Dense(2048)\n",
    "        self.fc_2 = tf.keras.layers.Dense(512)\n",
    "        self.fc_3 = tf.keras.layers.Dense(64)\n",
    "        self.fc_4 = tf.keras.layers.Dense(8, activation='softmax')\n",
    "\n",
    "        # used for attention\n",
    "        self.attention = LuongAttention(self.dec_units)\n",
    "        # self.attention = BahdanauAttention(self.dec_units)\n",
    "        # self.attention = DotAttention(self.dec_units)\n",
    "        \n",
    "\n",
    "    def call(self, hidden, enc_output):\n",
    "        context_vector, attention_weights = self.attention(hidden, enc_output)\n",
    "        output = self.fc_1(context_vector)\n",
    "        output = self.fc_2(output)\n",
    "        output = self.fc_3(output)\n",
    "        output = self.fc_4(output)\n",
    "\n",
    "        return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2706,
     "status": "ok",
     "timestamp": 1669356742614,
     "user": {
      "displayName": "陳皇佑",
      "userId": "01619903051591522740"
     },
     "user_tz": -480
    },
    "id": "wphbexE56Js8",
    "outputId": "1c03a0fe-5710-415d-9b5a-1c94b8d00a71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder output shape: (batch_size, vocab size) (64, 8)\n"
     ]
    }
   ],
   "source": [
    "decoder = Decoder(units, BATCH_SIZE)\n",
    "sample_decoder_output, _ = decoder(sample_hidden, sample_output)\n",
    "print('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0sV7vNCO6Lbt"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    loss_ = loss_object(real, pred)\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z86PNUbk6O_G"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inp, targ, enc_hidden):\n",
    "    loss = 0\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
    "\n",
    "        # passing enc_output to the decoder\n",
    "        predictions, _ = decoder(enc_hidden, enc_output)\n",
    "\n",
    "        loss = loss_function(targ, predictions)\n",
    "\n",
    "    # collect all trainable variables\n",
    "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
    "\n",
    "    # calculate the gradients for the whole variables\n",
    "    gradients = tape.gradient(loss, variables)\n",
    "\n",
    "    # apply the gradients on the variables\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237
    },
    "executionInfo": {
     "elapsed": 399,
     "status": "error",
     "timestamp": 1669370747875,
     "user": {
      "displayName": "陳皇佑",
      "userId": "01619903051591522740"
     },
     "user_tz": -480
    },
    "id": "gnSgDsl16Rpt",
    "outputId": "81157d43-ad62-4a18-873f-5f6da73a41a1"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-d7a50255733a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# get the initial hidden state of gru\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'time' is not defined"
     ]
    }
   ],
   "source": [
    "# set the epochs for training\n",
    "EPOCHS = 25\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "\n",
    "    # get the initial hidden state of gru\n",
    "    enc_hidden = encoder.initialize_hidden_state()\n",
    "    total_loss = 0\n",
    "\n",
    "    for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
    "        batch_loss = train_step(inp, targ, enc_hidden)\n",
    "        total_loss += batch_loss\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                                         batch,\n",
    "                                                         batch_loss.numpy()))\n",
    "\n",
    "    # saving (checkpoint) the model every 2 epochs\n",
    "    # if (epoch + 1) % 2 == 0:\n",
    "    #     checkpoint.save(file_prefix=checkpoint_prefix)\n",
    "\n",
    "    print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                        total_loss / steps_per_epoch))\n",
    "    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8k5Wjkwr6Z97"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def test_step(inp, enc_hidden):\n",
    "    with tf.GradientTape() as tape:\n",
    "        enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
    "        predictions, attention_weights = decoder(enc_hidden, enc_output)\n",
    "    return predictions, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ko4hfFvC6b6Z"
   },
   "outputs": [],
   "source": [
    "def evaluate(test_data):\n",
    "    enc_hidden = encoder.initialize_hidden_state()\n",
    "    \n",
    "    for batch, (inp, targ) in enumerate(test_data):\n",
    "        if len(inp) != BATCH_SIZE:\n",
    "            enc_hidden = tf.zeros((len(inp), units))\n",
    "        # make prediction\n",
    "        if batch == 0:\n",
    "            predictions, attention_weights = test_step(inp, enc_hidden)\n",
    "            predictions, attention_weights = predictions.numpy(), attention_weights.numpy()\n",
    "        else:\n",
    "            _predictions, _attention_weights = test_step(inp, enc_hidden)\n",
    "            _predictions, _attention_weights = _predictions.numpy(), _attention_weights.numpy()\n",
    "            predictions = np.concatenate((predictions, _predictions))\n",
    "            attention_weights = np.concatenate((attention_weights, _attention_weights))\n",
    "    \n",
    "    predictions = np.squeeze(predictions)\n",
    "    attention_weights = np.squeeze(attention_weights)\n",
    "    for i in range(len(predictions)):\n",
    "         max_v = np.max(predictions[i])\n",
    "         predictions[i][predictions[i]>=max_v] = 1\n",
    "         predictions[i][predictions[i]<max_v] = 0\n",
    "    return predictions, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1669363306596,
     "user": {
      "displayName": "陳皇佑",
      "userId": "01619903051591522740"
     },
     "user_tz": -480
    },
    "id": "DfRp4Xzx6eLw",
    "outputId": "3a470dc8-b83c-46fc-d5f7-24c5c57083f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8860098999357637\n"
     ]
    }
   ],
   "source": [
    "y_pred, attention_weights = evaluate(val_dataset)\n",
    "# print(y_pred)\n",
    "print('Accuracy: ', (y_pred == y_val).sum() /(len(y_val)*8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1669362373799,
     "user": {
      "displayName": "陳皇佑",
      "userId": "01619903051591522740"
     },
     "user_tz": -480
    },
    "id": "_PoZA8fjr__4",
    "outputId": "dccc7b99-1f42-4764-e691-4b1bce4bb834"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(y_pred[24500]))\n",
    "# print('Accuracy: ', (y_pred == y_val).sum() / (len(y_val)*8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XQGOgryCYZuG"
   },
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 383,
     "status": "ok",
     "timestamp": 1669361795109,
     "user": {
      "displayName": "陳皇佑",
      "userId": "01619903051591522740"
     },
     "user_tz": -480
    },
    "id": "sZNeHBHSt0rg",
    "outputId": "5de2e4c8-be04-43dd-c4f8-2c80cdc8620f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(411972, 15)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KcfYG754a3D5"
   },
   "outputs": [],
   "source": [
    "test_dataset = tf.data.Dataset.from_tensor_slices(X_test)\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE, drop_remainder=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ha8-5tUdzvwj"
   },
   "outputs": [],
   "source": [
    "def evaluate_test(test_data):\n",
    "    enc_hidden = encoder.initialize_hidden_state()\n",
    "    \n",
    "    for batch, (inp) in enumerate(test_data):\n",
    "        if len(inp) != BATCH_SIZE:\n",
    "            enc_hidden = tf.zeros((len(inp), units))\n",
    "        # make prediction\n",
    "        if batch == 0:\n",
    "            predictions, attention_weights = test_step(inp, enc_hidden)\n",
    "            predictions, attention_weights = predictions.numpy(), attention_weights.numpy()\n",
    "        else:\n",
    "            _predictions, _attention_weights = test_step(inp, enc_hidden)\n",
    "            _predictions, _attention_weights = _predictions.numpy(), _attention_weights.numpy()\n",
    "            predictions = np.concatenate((predictions, _predictions))\n",
    "            attention_weights = np.concatenate((attention_weights, _attention_weights))\n",
    "    \n",
    "    predictions = np.squeeze(predictions)\n",
    "    attention_weights = np.squeeze(attention_weights)\n",
    "    for i in range(len(predictions)):\n",
    "         max_v = np.max(predictions[i])\n",
    "         predictions[i][predictions[i]>=max_v] = 1\n",
    "         predictions[i][predictions[i]<max_v] = 0\n",
    "    return predictions, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eF4ycQs_uNFq"
   },
   "outputs": [],
   "source": [
    "for batch, (inp, targ) in enumerate(test_dataset):\n",
    "    print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5YzuAtxFYeVp"
   },
   "outputs": [],
   "source": [
    "y_pred, attention_weights = evaluate_test(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 530,
     "status": "ok",
     "timestamp": 1669363887628,
     "user": {
      "displayName": "陳皇佑",
      "userId": "01619903051591522740"
     },
     "user_tz": -480
    },
    "id": "Vpk8YtOUtUIw",
    "outputId": "f0c3bd02-22e3-4038-e518-9449e4ebb335"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['disgust' 'sadness' 'joy' ... 'anticipation' 'joy' 'joy']\n"
     ]
    }
   ],
   "source": [
    "idx = 23222\n",
    "# max_v = np.max(y_pred[idx])\n",
    "# y_pred[idx][y_pred[idx]>=max_v] = 1\n",
    "# y_pred[idx][y_pred[idx]<max_v] = 0\n",
    "# print(y_pred[idx].shape)\n",
    "# print(label_decode(label_encoder,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1669366429803,
     "user": {
      "displayName": "陳皇佑",
      "userId": "01619903051591522740"
     },
     "user_tz": -480
    },
    "id": "BEv--jS8vKoA",
    "outputId": "4cab0dd1-b63a-4333-ffd9-15b52c43f810"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-82cc89fd-29c0-49b8-947b-e52041803c00\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0x28cc61</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0x2db41f</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0x2466f6</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0x23f9e9</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0x1fb4e1</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411967</th>\n",
       "      <td>0x2c4dc2</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411968</th>\n",
       "      <td>0x31be7c</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411969</th>\n",
       "      <td>0x1ca58e</td>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411970</th>\n",
       "      <td>0x35c8ba</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411971</th>\n",
       "      <td>0x1d941b</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>411972 rows × 2 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-82cc89fd-29c0-49b8-947b-e52041803c00')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-82cc89fd-29c0-49b8-947b-e52041803c00 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-82cc89fd-29c0-49b8-947b-e52041803c00');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "              id       emotion\n",
       "0       0x28cc61       disgust\n",
       "1       0x2db41f       sadness\n",
       "2       0x2466f6           joy\n",
       "3       0x23f9e9       disgust\n",
       "4       0x1fb4e1       disgust\n",
       "...          ...           ...\n",
       "411967  0x2c4dc2           joy\n",
       "411968  0x31be7c           joy\n",
       "411969  0x1ca58e  anticipation\n",
       "411970  0x35c8ba           joy\n",
       "411971  0x1d941b           joy\n",
       "\n",
       "[411972 rows x 2 columns]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_emo = label_decode(label_encoder,y_pred)\n",
    "y_pred_emo = pd.Series(y_pred_emo)\n",
    "id = df_test['tweet_id']\n",
    "assert len(id)==len(y_pred_emo)\n",
    "pred_result = pd.concat([id, y_pred_emo], axis = 1)\n",
    "pred_result.rename(columns={'tweet_id':'id', 0:'emotion'}, inplace=True)\n",
    "pred_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AqcOobaT1JiB"
   },
   "outputs": [],
   "source": [
    "pred_result.to_csv('/content/drive/MyDrive/DMLab2/data/att_result.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xv4gTG8B43C2"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOXE8xyJy0BZCvyGaShmaIN",
   "provenance": [
    {
     "file_id": "1MywtUcbLPavSxIZMSpos7uj5dh3IG-ab",
     "timestamp": 1669271897901
    }
   ]
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
