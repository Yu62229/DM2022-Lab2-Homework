{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Student Information\n",
    "Name:Èô≥Áöá‰Ωë\n",
    "\n",
    "Student ID:108062229    \n",
    "\n",
    "GitHub ID:Yu62229\n",
    "\n",
    "Kaggle name:yu62229\n",
    "\n",
    "Kaggle private scoreboard snapshot:\n",
    "\n",
    "[Snapshot](img/pic0.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. First: __This part is worth 30% of your grade.__ Do the **take home** exercises in the [DM2022-Lab2-master Repo](https://github.com/keziatamus/DM2022-Lab2-Master). You may need to copy some cells from the Lab notebook to this notebook. \n",
    "\n",
    "\n",
    "2. Second: __This part is worth 30% of your grade.__ Participate in the in-class [Kaggle Competition](https://www.kaggle.com/competitions/dm2022-isa5810-lab2-homework) regarding Emotion Recognition on Twitter by this link https://www.kaggle.com/t/2b0d14a829f340bc88d2660dc602d4bd. The scoring will be given according to your place in the Private Leaderboard ranking: \n",
    "    - **Bottom 40%**: Get 20% of the 30% available for this section.\n",
    "\n",
    "    - **Top 41% - 100%**: Get (60-x)/6 + 20 points, where x is your ranking in the leaderboard (ie. If you rank 3rd your score will be (60-3)/6 + 20 = 29.5% out of 30%)   \n",
    "    Submit your last submission __BEFORE the deadline (Nov. 22th 11:59 pm, Tuesday)_. Make sure to take a screenshot of your position at the end of the competition and store it as '''pic0.png''' under the **img** folder of this repository and rerun the cell **Student Information**.\n",
    "    \n",
    "\n",
    "3. Third: __This part is worth 30% of your grade.__ A report of your work developping the model for the competition (You can use code and comment it). This report should include what your preprocessing steps, the feature engineering steps and an explanation of your model. You can also mention different things you tried and insights you gained. \n",
    "\n",
    "\n",
    "4. Fourth: __This part is worth 10% of your grade.__ It's hard for us to follow if your code is messy :'(, so please **tidy up your notebook** and **add minimal comments where needed**.\n",
    "\n",
    "\n",
    "Upload your files to your repository then submit the link to it on the corresponding e-learn assignment.\n",
    "\n",
    "Make sure to commit and save your changes to your repository __BEFORE the deadline (Nov. 25th 11:59 pm, Friday)__. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "repository: https://github.com/Yu62229/DM2022-Lab2-Master/blob/main/DM2022-Lab2-Master.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Begin Assignment Here\n",
    "import pandas as pd\n",
    "\n",
    "raw_data_js = pd.read_json('data/tweets_DM.json', orient='values', lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_score</th>\n",
       "      <th>_index</th>\n",
       "      <th>_source</th>\n",
       "      <th>_crawldate</th>\n",
       "      <th>_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>391</td>\n",
       "      <td>hashtag_tweets</td>\n",
       "      <td>{'tweet': {'hashtags': ['Snapchat'], 'tweet_id...</td>\n",
       "      <td>2015-05-23 11:42:47</td>\n",
       "      <td>tweets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>433</td>\n",
       "      <td>hashtag_tweets</td>\n",
       "      <td>{'tweet': {'hashtags': ['freepress', 'TrumpLeg...</td>\n",
       "      <td>2016-01-28 04:52:09</td>\n",
       "      <td>tweets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>232</td>\n",
       "      <td>hashtag_tweets</td>\n",
       "      <td>{'tweet': {'hashtags': ['bibleverse'], 'tweet_...</td>\n",
       "      <td>2017-12-25 04:39:20</td>\n",
       "      <td>tweets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>376</td>\n",
       "      <td>hashtag_tweets</td>\n",
       "      <td>{'tweet': {'hashtags': [], 'tweet_id': '0x1cd5...</td>\n",
       "      <td>2016-01-24 23:53:05</td>\n",
       "      <td>tweets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>989</td>\n",
       "      <td>hashtag_tweets</td>\n",
       "      <td>{'tweet': {'hashtags': [], 'tweet_id': '0x2de2...</td>\n",
       "      <td>2016-01-08 17:18:59</td>\n",
       "      <td>tweets</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   _score          _index                                            _source  \\\n",
       "0     391  hashtag_tweets  {'tweet': {'hashtags': ['Snapchat'], 'tweet_id...   \n",
       "1     433  hashtag_tweets  {'tweet': {'hashtags': ['freepress', 'TrumpLeg...   \n",
       "2     232  hashtag_tweets  {'tweet': {'hashtags': ['bibleverse'], 'tweet_...   \n",
       "3     376  hashtag_tweets  {'tweet': {'hashtags': [], 'tweet_id': '0x1cd5...   \n",
       "4     989  hashtag_tweets  {'tweet': {'hashtags': [], 'tweet_id': '0x2de2...   \n",
       "\n",
       "            _crawldate   _type  \n",
       "0  2015-05-23 11:42:47  tweets  \n",
       "1  2016-01-28 04:52:09  tweets  \n",
       "2  2017-12-25 04:39:20  tweets  \n",
       "3  2016-01-24 23:53:05  tweets  \n",
       "4  2016-01-08 17:18:59  tweets  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data_js.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check there are only one value in _type & _index\n",
    "len(raw_data_js[(raw_data_js[\"_type\"] != 'tweets')] )\n",
    "len(raw_data_js[(raw_data_js[\"_index\"] != 'hashtag_tweets')] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_score</th>\n",
       "      <th>_source</th>\n",
       "      <th>_crawldate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>391</td>\n",
       "      <td>{'tweet': {'hashtags': ['Snapchat'], 'tweet_id...</td>\n",
       "      <td>2015-05-23 11:42:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>433</td>\n",
       "      <td>{'tweet': {'hashtags': ['freepress', 'TrumpLeg...</td>\n",
       "      <td>2016-01-28 04:52:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>232</td>\n",
       "      <td>{'tweet': {'hashtags': ['bibleverse'], 'tweet_...</td>\n",
       "      <td>2017-12-25 04:39:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>376</td>\n",
       "      <td>{'tweet': {'hashtags': [], 'tweet_id': '0x1cd5...</td>\n",
       "      <td>2016-01-24 23:53:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>989</td>\n",
       "      <td>{'tweet': {'hashtags': [], 'tweet_id': '0x2de2...</td>\n",
       "      <td>2016-01-08 17:18:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867530</th>\n",
       "      <td>827</td>\n",
       "      <td>{'tweet': {'hashtags': ['mixedfeeling', 'butim...</td>\n",
       "      <td>2015-05-12 12:51:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867531</th>\n",
       "      <td>368</td>\n",
       "      <td>{'tweet': {'hashtags': [], 'tweet_id': '0x29d0...</td>\n",
       "      <td>2017-10-02 17:54:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867532</th>\n",
       "      <td>498</td>\n",
       "      <td>{'tweet': {'hashtags': [], 'tweet_id': '0x2a6a...</td>\n",
       "      <td>2016-10-10 11:04:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867533</th>\n",
       "      <td>840</td>\n",
       "      <td>{'tweet': {'hashtags': [], 'tweet_id': '0x24fa...</td>\n",
       "      <td>2016-09-02 14:25:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1867534</th>\n",
       "      <td>360</td>\n",
       "      <td>{'tweet': {'hashtags': ['Sundayvibes'], 'tweet...</td>\n",
       "      <td>2016-11-16 01:40:07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1867535 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         _score                                            _source  \\\n",
       "0           391  {'tweet': {'hashtags': ['Snapchat'], 'tweet_id...   \n",
       "1           433  {'tweet': {'hashtags': ['freepress', 'TrumpLeg...   \n",
       "2           232  {'tweet': {'hashtags': ['bibleverse'], 'tweet_...   \n",
       "3           376  {'tweet': {'hashtags': [], 'tweet_id': '0x1cd5...   \n",
       "4           989  {'tweet': {'hashtags': [], 'tweet_id': '0x2de2...   \n",
       "...         ...                                                ...   \n",
       "1867530     827  {'tweet': {'hashtags': ['mixedfeeling', 'butim...   \n",
       "1867531     368  {'tweet': {'hashtags': [], 'tweet_id': '0x29d0...   \n",
       "1867532     498  {'tweet': {'hashtags': [], 'tweet_id': '0x2a6a...   \n",
       "1867533     840  {'tweet': {'hashtags': [], 'tweet_id': '0x24fa...   \n",
       "1867534     360  {'tweet': {'hashtags': ['Sundayvibes'], 'tweet...   \n",
       "\n",
       "                  _crawldate  \n",
       "0        2015-05-23 11:42:47  \n",
       "1        2016-01-28 04:52:09  \n",
       "2        2017-12-25 04:39:20  \n",
       "3        2016-01-24 23:53:05  \n",
       "4        2016-01-08 17:18:59  \n",
       "...                      ...  \n",
       "1867530  2015-05-12 12:51:52  \n",
       "1867531  2017-10-02 17:54:04  \n",
       "1867532  2016-10-10 11:04:32  \n",
       "1867533  2016-09-02 14:25:06  \n",
       "1867534  2016-11-16 01:40:07  \n",
       "\n",
       "[1867535 rows x 3 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_js = raw_data_js.drop(columns = ['_index', '_type'])\n",
    "data_js"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = data_js['_source']\n",
    "def get_attr(source_data):\n",
    "    data = source_data['tweet']\n",
    "    attr = {}\n",
    "    for k, v in data.items():\n",
    "        attr[k] = v\n",
    "    return attr\n",
    "new_data = pd.DataFrame(source.map(get_attr).tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hashtags</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Snapchat]</td>\n",
       "      <td>0x376b20</td>\n",
       "      <td>People who post \"add me on #Snapchat\" must be ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[freepress, TrumpLegacy, CNN]</td>\n",
       "      <td>0x2d5350</td>\n",
       "      <td>@brianklaas As we see, Trump is dangerous to #...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[bibleverse]</td>\n",
       "      <td>0x28b412</td>\n",
       "      <td>Confident of your obedience, I write to you, k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[]</td>\n",
       "      <td>0x1cd5b0</td>\n",
       "      <td>Now ISSA is stalking Tasha üòÇüòÇüòÇ &lt;LH&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[]</td>\n",
       "      <td>0x2de201</td>\n",
       "      <td>\"Trust is not the same as faith. A friend is s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        hashtags  tweet_id  \\\n",
       "0                     [Snapchat]  0x376b20   \n",
       "1  [freepress, TrumpLegacy, CNN]  0x2d5350   \n",
       "2                   [bibleverse]  0x28b412   \n",
       "3                             []  0x1cd5b0   \n",
       "4                             []  0x2de201   \n",
       "\n",
       "                                                text  \n",
       "0  People who post \"add me on #Snapchat\" must be ...  \n",
       "1  @brianklaas As we see, Trump is dangerous to #...  \n",
       "2  Confident of your obedience, I write to you, k...  \n",
       "3                Now ISSA is stalking Tasha üòÇüòÇüòÇ <LH>  \n",
       "4  \"Trust is not the same as faith. A friend is s...  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['_source'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [55]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdata_js\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_source\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m p_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([data_js, new_data], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      3\u001b[0m p_data\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\lab1\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\lab1\\lib\\site-packages\\pandas\\core\\frame.py:4957\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4809\u001b[0m \u001b[38;5;129m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, allowed_args\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m   4810\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[0;32m   4811\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4818\u001b[0m     errors: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   4819\u001b[0m ):\n\u001b[0;32m   4820\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4821\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   4822\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4955\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   4956\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4957\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4958\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4959\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4960\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4961\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4962\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4963\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4964\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4965\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\lab1\\lib\\site-packages\\pandas\\core\\generic.py:4267\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4265\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   4266\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 4267\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4269\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m   4270\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\lab1\\lib\\site-packages\\pandas\\core\\generic.py:4311\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, consolidate, only_slice)\u001b[0m\n\u001b[0;32m   4309\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4310\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4311\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4312\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4314\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4315\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\lab1\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6661\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   6659\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m   6660\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 6661\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(labels[mask])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6662\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[0;32m   6663\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['_source'] not found in axis\""
     ]
    }
   ],
   "source": [
    "data_js.drop(columns = ['_source'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_score</th>\n",
       "      <th>_crawldate</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>391</td>\n",
       "      <td>2015-05-23 11:42:47</td>\n",
       "      <td>[Snapchat]</td>\n",
       "      <td>0x376b20</td>\n",
       "      <td>People who post \"add me on #Snapchat\" must be ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>433</td>\n",
       "      <td>2016-01-28 04:52:09</td>\n",
       "      <td>[freepress, TrumpLegacy, CNN]</td>\n",
       "      <td>0x2d5350</td>\n",
       "      <td>@brianklaas As we see, Trump is dangerous to #...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>232</td>\n",
       "      <td>2017-12-25 04:39:20</td>\n",
       "      <td>[bibleverse]</td>\n",
       "      <td>0x28b412</td>\n",
       "      <td>Confident of your obedience, I write to you, k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>376</td>\n",
       "      <td>2016-01-24 23:53:05</td>\n",
       "      <td>[]</td>\n",
       "      <td>0x1cd5b0</td>\n",
       "      <td>Now ISSA is stalking Tasha üòÇüòÇüòÇ &lt;LH&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>989</td>\n",
       "      <td>2016-01-08 17:18:59</td>\n",
       "      <td>[]</td>\n",
       "      <td>0x2de201</td>\n",
       "      <td>\"Trust is not the same as faith. A friend is s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   _score           _crawldate                       hashtags  tweet_id  \\\n",
       "0     391  2015-05-23 11:42:47                     [Snapchat]  0x376b20   \n",
       "1     433  2016-01-28 04:52:09  [freepress, TrumpLegacy, CNN]  0x2d5350   \n",
       "2     232  2017-12-25 04:39:20                   [bibleverse]  0x28b412   \n",
       "3     376  2016-01-24 23:53:05                             []  0x1cd5b0   \n",
       "4     989  2016-01-08 17:18:59                             []  0x2de201   \n",
       "\n",
       "                                                text  \n",
       "0  People who post \"add me on #Snapchat\" must be ...  \n",
       "1  @brianklaas As we see, Trump is dangerous to #...  \n",
       "2  Confident of your obedience, I write to you, k...  \n",
       "3                Now ISSA is stalking Tasha üòÇüòÇüòÇ <LH>  \n",
       "4  \"Trust is not the same as faith. A friend is s...  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_data = pd.concat([data_js, new_data], axis=1)\n",
    "p_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_data = p_data[['tweet_id', 'hashtags', 'text', '_score', '_crawldate']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_data = p_data.sort_values('tweet_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hashtags</th>\n",
       "      <th>text</th>\n",
       "      <th>_score</th>\n",
       "      <th>_crawldate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0x1c7f0f</th>\n",
       "      <td>[]</td>\n",
       "      <td>@JZED74 While inappropriate AF, he likely wasn...</td>\n",
       "      <td>62</td>\n",
       "      <td>2017-05-14 11:39:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0x1c7f10</th>\n",
       "      <td>[BlackMirror]</td>\n",
       "      <td>o m g Shut Up And Dance though #BlackMirror &lt;LH&gt;</td>\n",
       "      <td>242</td>\n",
       "      <td>2015-05-16 10:36:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0x1c7f11</th>\n",
       "      <td>[twitch, Destinybeta, Destiny, Destiny2, Desti...</td>\n",
       "      <td>On #twitch &lt;LH&gt; on the #Destinybeta #Destiny #...</td>\n",
       "      <td>915</td>\n",
       "      <td>2016-10-15 20:46:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0x1c7f12</th>\n",
       "      <td>[]</td>\n",
       "      <td>I tried to figure out why you mean so much to ...</td>\n",
       "      <td>756</td>\n",
       "      <td>2016-02-14 15:55:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0x1c7f13</th>\n",
       "      <td>[auspol, fizza]</td>\n",
       "      <td>The only ‚Äúbig plan‚Äù you ever had in your life,...</td>\n",
       "      <td>213</td>\n",
       "      <td>2016-07-25 17:05:35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   hashtags  \\\n",
       "tweet_id                                                      \n",
       "0x1c7f0f                                                 []   \n",
       "0x1c7f10                                      [BlackMirror]   \n",
       "0x1c7f11  [twitch, Destinybeta, Destiny, Destiny2, Desti...   \n",
       "0x1c7f12                                                 []   \n",
       "0x1c7f13                                    [auspol, fizza]   \n",
       "\n",
       "                                                       text  _score  \\\n",
       "tweet_id                                                              \n",
       "0x1c7f0f  @JZED74 While inappropriate AF, he likely wasn...      62   \n",
       "0x1c7f10   o m g Shut Up And Dance though #BlackMirror <LH>     242   \n",
       "0x1c7f11  On #twitch <LH> on the #Destinybeta #Destiny #...     915   \n",
       "0x1c7f12  I tried to figure out why you mean so much to ...     756   \n",
       "0x1c7f13  The only ‚Äúbig plan‚Äù you ever had in your life,...     213   \n",
       "\n",
       "                   _crawldate  \n",
       "tweet_id                       \n",
       "0x1c7f0f  2017-05-14 11:39:43  \n",
       "0x1c7f10  2015-05-16 10:36:47  \n",
       "0x1c7f11  2016-10-15 20:46:37  \n",
       "0x1c7f12  2016-02-14 15:55:45  \n",
       "0x1c7f13  2016-07-25 17:05:35  "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# p_data.set_index('tweet_id', inplace=True)\n",
    "p_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ident = pd.read_csv('data/data_identification.csv', index_col='tweet_id')\n",
    "train_label = pd.read_csv('data/emotion.csv', index_col='tweet_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iden = data_ident[data_ident['identification']=='train']\n",
    "test_iden = data_ident[data_ident['identification']=='test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_iden)==len(train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identification</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0x29e452</th>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0x2b3819</th>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0x2a2acc</th>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0x2a8830</th>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0x20b21d</th>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         identification\n",
       "tweet_id               \n",
       "0x29e452          train\n",
       "0x2b3819          train\n",
       "0x2a2acc          train\n",
       "0x2a8830          train\n",
       "0x20b21d          train"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_iden.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = p_data.loc[test_iden.index.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = p_data.loc[train_iden.index.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)==len(train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hashtags</th>\n",
       "      <th>text</th>\n",
       "      <th>_score</th>\n",
       "      <th>_crawldate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0x29e452</th>\n",
       "      <td>[]</td>\n",
       "      <td>Huge Respectüñí @JohnnyVegasReal talking about l...</td>\n",
       "      <td>809</td>\n",
       "      <td>2015-01-17 03:07:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0x2b3819</th>\n",
       "      <td>[spateradio, app]</td>\n",
       "      <td>Yoooo we hit all our monthly goals with the ne...</td>\n",
       "      <td>808</td>\n",
       "      <td>2016-07-02 09:34:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0x2a2acc</th>\n",
       "      <td>[]</td>\n",
       "      <td>@KIDSNTS @PICU_BCH @uhbcomms @BWCHBoss Well do...</td>\n",
       "      <td>16</td>\n",
       "      <td>2016-08-15 18:18:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0x2a8830</th>\n",
       "      <td>[PUBG, GamersUnite, twitch, BeHealthy, StayPos...</td>\n",
       "      <td>Come join @ambushman27 on #PUBG while he striv...</td>\n",
       "      <td>768</td>\n",
       "      <td>2017-02-11 08:49:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0x20b21d</th>\n",
       "      <td>[strength, bones, God]</td>\n",
       "      <td>@fanshixieen2014 Blessings!My #strength little...</td>\n",
       "      <td>70</td>\n",
       "      <td>2016-11-23 05:37:10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   hashtags  \\\n",
       "tweet_id                                                      \n",
       "0x29e452                                                 []   \n",
       "0x2b3819                                  [spateradio, app]   \n",
       "0x2a2acc                                                 []   \n",
       "0x2a8830  [PUBG, GamersUnite, twitch, BeHealthy, StayPos...   \n",
       "0x20b21d                             [strength, bones, God]   \n",
       "\n",
       "                                                       text  _score  \\\n",
       "tweet_id                                                              \n",
       "0x29e452  Huge Respectüñí @JohnnyVegasReal talking about l...     809   \n",
       "0x2b3819  Yoooo we hit all our monthly goals with the ne...     808   \n",
       "0x2a2acc  @KIDSNTS @PICU_BCH @uhbcomms @BWCHBoss Well do...      16   \n",
       "0x2a8830  Come join @ambushman27 on #PUBG while he striv...     768   \n",
       "0x20b21d  @fanshixieen2014 Blessings!My #strength little...      70   \n",
       "\n",
       "                   _crawldate  \n",
       "tweet_id                       \n",
       "0x29e452  2015-01-17 03:07:03  \n",
       "0x2b3819  2016-07-02 09:34:06  \n",
       "0x2a2acc  2016-08-15 18:18:39  \n",
       "0x2a8830  2017-02-11 08:49:46  \n",
       "0x20b21d  2016-11-23 05:37:10  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.to_pickle('data/train_data.pkl')\n",
    "train_label.to_pickle('data/train_label.pkl')\n",
    "test_data.to_pickle('data/test_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [84]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_data_colab \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([\u001b[43mtrain_data\u001b[49m, train_label], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_data' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_pickle('data/train_data.pkl')\n",
    "label_df = pd.read_pickle('data/train_label.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_colab = pd.concat([train_df, label_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_colab.to_csv('data/train_data_colab.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('anger',\n",
       "           emotion\n",
       "  tweet_id        \n",
       "  0x27b6b2   anger\n",
       "  0x351172   anger\n",
       "  0x2c7fe7   anger\n",
       "  0x25da50   anger\n",
       "  0x271671   anger\n",
       "  ...          ...\n",
       "  0x2a6bb8   anger\n",
       "  0x217acf   anger\n",
       "  0x26070e   anger\n",
       "  0x2c6758   anger\n",
       "  0x35b719   anger\n",
       "  \n",
       "  [39867 rows x 1 columns]),\n",
       " ('anticipation',\n",
       "                 emotion\n",
       "  tweet_id              \n",
       "  0x296183  anticipation\n",
       "  0x2ee1dd  anticipation\n",
       "  0x215b2e  anticipation\n",
       "  0x255135  anticipation\n",
       "  0x37db4e  anticipation\n",
       "  ...                ...\n",
       "  0x33720c  anticipation\n",
       "  0x347bad  anticipation\n",
       "  0x2fd134  anticipation\n",
       "  0x273820  anticipation\n",
       "  0x2fb282  anticipation\n",
       "  \n",
       "  [248935 rows x 1 columns]),\n",
       " ('disgust',\n",
       "            emotion\n",
       "  tweet_id         \n",
       "  0x368b73  disgust\n",
       "  0x361411  disgust\n",
       "  0x25e867  disgust\n",
       "  0x31bb2a  disgust\n",
       "  0x380813  disgust\n",
       "  ...           ...\n",
       "  0x30a14f  disgust\n",
       "  0x2e80fe  disgust\n",
       "  0x2b60ee  disgust\n",
       "  0x24f4c4  disgust\n",
       "  0x2b06c6  disgust\n",
       "  \n",
       "  [139101 rows x 1 columns]),\n",
       " ('fear',\n",
       "           emotion\n",
       "  tweet_id        \n",
       "  0x30e5c4    fear\n",
       "  0x2f813e    fear\n",
       "  0x26f223    fear\n",
       "  0x36899f    fear\n",
       "  0x301b4f    fear\n",
       "  ...          ...\n",
       "  0x2e698c    fear\n",
       "  0x2efd29    fear\n",
       "  0x2b12da    fear\n",
       "  0x1e269e    fear\n",
       "  0x360b99    fear\n",
       "  \n",
       "  [63999 rows x 1 columns]),\n",
       " ('joy',\n",
       "           emotion\n",
       "  tweet_id        \n",
       "  0x2bd6e1     joy\n",
       "  0x34cd80     joy\n",
       "  0x349b83     joy\n",
       "  0x213b5e     joy\n",
       "  0x31a0e7     joy\n",
       "  ...          ...\n",
       "  0x352c43     joy\n",
       "  0x319e51     joy\n",
       "  0x38dba0     joy\n",
       "  0x300ea2     joy\n",
       "  0x22eecf     joy\n",
       "  \n",
       "  [516017 rows x 1 columns]),\n",
       " ('sadness',\n",
       "            emotion\n",
       "  tweet_id         \n",
       "  0x3140b1  sadness\n",
       "  0x33f099  sadness\n",
       "  0x2ae7b7  sadness\n",
       "  0x2b193b  sadness\n",
       "  0x270297  sadness\n",
       "  ...           ...\n",
       "  0x3022ab  sadness\n",
       "  0x1ec015  sadness\n",
       "  0x3024a9  sadness\n",
       "  0x1e38a5  sadness\n",
       "  0x26e8bd  sadness\n",
       "  \n",
       "  [193437 rows x 1 columns]),\n",
       " ('surprise',\n",
       "             emotion\n",
       "  tweet_id          \n",
       "  0x311f20  surprise\n",
       "  0x2bc2e2  surprise\n",
       "  0x2403e3  surprise\n",
       "  0x248940  surprise\n",
       "  0x25dd03  surprise\n",
       "  ...            ...\n",
       "  0x33a8bf  surprise\n",
       "  0x22033b  surprise\n",
       "  0x2ee98e  surprise\n",
       "  0x222f8b  surprise\n",
       "  0x2d0302  surprise\n",
       "  \n",
       "  [48729 rows x 1 columns]),\n",
       " ('trust',\n",
       "           emotion\n",
       "  tweet_id        \n",
       "  0x2408d4   trust\n",
       "  0x1e16a0   trust\n",
       "  0x255bbd   trust\n",
       "  0x1c9da9   trust\n",
       "  0x21bf40   trust\n",
       "  ...          ...\n",
       "  0x2cb529   trust\n",
       "  0x3809df   trust\n",
       "  0x2a7ab2   trust\n",
       "  0x236f8d   trust\n",
       "  0x2e7b96   trust\n",
       "  \n",
       "  [205478 rows x 1 columns])]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(label_df.groupby(['emotion']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = label_df.groupby('emotion')    \n",
    "gb_data = [gb.get_group(x) for x in gb.groups]\n",
    "small_label = gb_data[0].sample(500)\n",
    "for i in range(1, 8):\n",
    "    new_data = gb_data[i].sample(500)\n",
    "    small_label = pd.concat([small_label, new_data], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "small_label = shuffle(small_label, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0x203ae5</th>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0x32bdf0</th>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0x2919b5</th>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0x340a37</th>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0x3649bd</th>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0x26527f</th>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0x283aa5</th>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0x1fa355</th>\n",
       "      <td>anticipation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0x281002</th>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0x34d49b</th>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows √ó 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               emotion\n",
       "tweet_id              \n",
       "0x203ae5           joy\n",
       "0x32bdf0  anticipation\n",
       "0x2919b5         anger\n",
       "0x340a37       sadness\n",
       "0x3649bd  anticipation\n",
       "...                ...\n",
       "0x26527f          fear\n",
       "0x283aa5       sadness\n",
       "0x1fa355  anticipation\n",
       "0x281002       disgust\n",
       "0x34d49b         anger\n",
       "\n",
       "[4000 rows x 1 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hashtags</th>\n",
       "      <th>text</th>\n",
       "      <th>_score</th>\n",
       "      <th>_crawldate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0x203ae5</th>\n",
       "      <td>[Supernatural]</td>\n",
       "      <td>We've had such a wealth of supporting characte...</td>\n",
       "      <td>696</td>\n",
       "      <td>2017-04-02 13:14:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0x32bdf0</th>\n",
       "      <td>[humbly, wholeheartedly, ILove, Shows, ButGod]</td>\n",
       "      <td>&lt;LH&gt; I just want to #humbly #wholeheartedly &lt;L...</td>\n",
       "      <td>29</td>\n",
       "      <td>2016-01-16 16:38:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0x2919b5</th>\n",
       "      <td>[YouNeedToTrustMe, StopBeingInsecure]</td>\n",
       "      <td>It's seriously annoying when you CONSTANTLY ge...</td>\n",
       "      <td>465</td>\n",
       "      <td>2017-10-08 02:45:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0x340a37</th>\n",
       "      <td>[Sad]</td>\n",
       "      <td>@bartos_brian @realDonaldTrump Not the Donald ...</td>\n",
       "      <td>619</td>\n",
       "      <td>2017-10-23 16:26:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0x3649bd</th>\n",
       "      <td>[ifyoujustbelieve]</td>\n",
       "      <td>Keep your eyes on the Savior and you can walk ...</td>\n",
       "      <td>24</td>\n",
       "      <td>2017-09-23 04:09:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0x26527f</th>\n",
       "      <td>[]</td>\n",
       "      <td>Now playing &lt;LH&gt; - Foreign Policy on North Tex...</td>\n",
       "      <td>386</td>\n",
       "      <td>2016-06-28 19:33:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0x283aa5</th>\n",
       "      <td>[]</td>\n",
       "      <td>I scored a 44 tonight bowling &lt;LH&gt;</td>\n",
       "      <td>555</td>\n",
       "      <td>2017-01-01 10:01:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0x1fa355</th>\n",
       "      <td>[]</td>\n",
       "      <td>@kennethralls1 Thank you VERY much for the fol...</td>\n",
       "      <td>825</td>\n",
       "      <td>2017-11-17 18:16:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0x281002</th>\n",
       "      <td>[WomensEqualityDay, HurricaneHarvery, JoeArpai...</td>\n",
       "      <td>A &lt;LH&gt; #WomensEqualityDay is being overshadowe...</td>\n",
       "      <td>369</td>\n",
       "      <td>2017-10-28 02:03:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0x34d49b</th>\n",
       "      <td>[AppleWatch]</td>\n",
       "      <td>Hey @Apple, what is the secret to not hit the ...</td>\n",
       "      <td>929</td>\n",
       "      <td>2017-04-15 21:06:46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   hashtags  \\\n",
       "tweet_id                                                      \n",
       "0x203ae5                                     [Supernatural]   \n",
       "0x32bdf0     [humbly, wholeheartedly, ILove, Shows, ButGod]   \n",
       "0x2919b5              [YouNeedToTrustMe, StopBeingInsecure]   \n",
       "0x340a37                                              [Sad]   \n",
       "0x3649bd                                 [ifyoujustbelieve]   \n",
       "...                                                     ...   \n",
       "0x26527f                                                 []   \n",
       "0x283aa5                                                 []   \n",
       "0x1fa355                                                 []   \n",
       "0x281002  [WomensEqualityDay, HurricaneHarvery, JoeArpai...   \n",
       "0x34d49b                                       [AppleWatch]   \n",
       "\n",
       "                                                       text  _score  \\\n",
       "tweet_id                                                              \n",
       "0x203ae5  We've had such a wealth of supporting characte...     696   \n",
       "0x32bdf0  <LH> I just want to #humbly #wholeheartedly <L...      29   \n",
       "0x2919b5  It's seriously annoying when you CONSTANTLY ge...     465   \n",
       "0x340a37  @bartos_brian @realDonaldTrump Not the Donald ...     619   \n",
       "0x3649bd  Keep your eyes on the Savior and you can walk ...      24   \n",
       "...                                                     ...     ...   \n",
       "0x26527f  Now playing <LH> - Foreign Policy on North Tex...     386   \n",
       "0x283aa5                 I scored a 44 tonight bowling <LH>     555   \n",
       "0x1fa355  @kennethralls1 Thank you VERY much for the fol...     825   \n",
       "0x281002  A <LH> #WomensEqualityDay is being overshadowe...     369   \n",
       "0x34d49b  Hey @Apple, what is the secret to not hit the ...     929   \n",
       "\n",
       "                   _crawldate  \n",
       "tweet_id                       \n",
       "0x203ae5  2017-04-02 13:14:54  \n",
       "0x32bdf0  2016-01-16 16:38:40  \n",
       "0x2919b5  2017-10-08 02:45:07  \n",
       "0x340a37  2017-10-23 16:26:48  \n",
       "0x3649bd  2017-09-23 04:09:13  \n",
       "...                       ...  \n",
       "0x26527f  2016-06-28 19:33:31  \n",
       "0x283aa5  2017-01-01 10:01:15  \n",
       "0x1fa355  2017-11-17 18:16:10  \n",
       "0x281002  2017-10-28 02:03:04  \n",
       "0x34d49b  2017-04-15 21:06:46  \n",
       "\n",
       "[4000 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_train = train_df.loc[small_label.index]\n",
    "small_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\lab1\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:524: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1455563, 500)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# build analyzers (bag-of-words)\n",
    "BOW_500 = CountVectorizer(max_features=500, tokenizer=nltk.word_tokenize) \n",
    "\n",
    "# apply analyzer to training data\n",
    "BOW_500.fit(small_train['text'])\n",
    "\n",
    "train_data_BOW_features_500 = BOW_500.transform(small_train['text'])\n",
    "\n",
    "## check dimension\n",
    "train_data_BOW_features_500.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hashtags</th>\n",
       "      <th>text</th>\n",
       "      <th>_score</th>\n",
       "      <th>_crawldate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0x1c7f10</th>\n",
       "      <td>[BlackMirror]</td>\n",
       "      <td>o m g Shut Up And Dance though #BlackMirror &lt;LH&gt;</td>\n",
       "      <td>242</td>\n",
       "      <td>2015-05-16 10:36:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0x1c7f11</th>\n",
       "      <td>[twitch, Destinybeta, Destiny, Destiny2, Desti...</td>\n",
       "      <td>On #twitch &lt;LH&gt; on the #Destinybeta #Destiny #...</td>\n",
       "      <td>915</td>\n",
       "      <td>2016-10-15 20:46:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0x1c7f14</th>\n",
       "      <td>[]</td>\n",
       "      <td>A nice sunny wak this morning not many &lt;LH&gt; ar...</td>\n",
       "      <td>939</td>\n",
       "      <td>2016-07-04 07:22:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0x1c7f15</th>\n",
       "      <td>[Confession, NationalCandyCornDay, CouldEatThe...</td>\n",
       "      <td>I'm one of those people who love candy corn......</td>\n",
       "      <td>181</td>\n",
       "      <td>2016-04-16 12:53:40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0x1c7f16</th>\n",
       "      <td>[]</td>\n",
       "      <td>@metmuseum What are these? They look like some...</td>\n",
       "      <td>970</td>\n",
       "      <td>2017-04-22 17:50:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0x38fe18</th>\n",
       "      <td>[]</td>\n",
       "      <td>@LJPBR @FifthHarmony Um  My vote For @FifthHar...</td>\n",
       "      <td>922</td>\n",
       "      <td>2016-12-06 11:10:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0x38fe19</th>\n",
       "      <td>[WesHoolahan, WALvIRL, COYBIG]</td>\n",
       "      <td>Where is #WesHoolahan?!  #WALvIRL #COYBIG &lt;LH&gt;</td>\n",
       "      <td>77</td>\n",
       "      <td>2015-02-01 18:04:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0x38fe1a</th>\n",
       "      <td>[not, maga]</td>\n",
       "      <td>@mattmfm Fake news! &lt;LH&gt; propagated by Tumpkin...</td>\n",
       "      <td>25</td>\n",
       "      <td>2016-12-20 17:19:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0x38fe1c</th>\n",
       "      <td>[]</td>\n",
       "      <td>..today was brutal  ..#Hungover</td>\n",
       "      <td>639</td>\n",
       "      <td>2016-09-13 06:31:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0x38fe1d</th>\n",
       "      <td>[redheadproblems, ouch, burnt]</td>\n",
       "      <td>Love it when I sun burn my forehead!! NOT!! üò´üò±...</td>\n",
       "      <td>630</td>\n",
       "      <td>2016-09-19 14:35:01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1455563 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   hashtags  \\\n",
       "tweet_id                                                      \n",
       "0x1c7f10                                      [BlackMirror]   \n",
       "0x1c7f11  [twitch, Destinybeta, Destiny, Destiny2, Desti...   \n",
       "0x1c7f14                                                 []   \n",
       "0x1c7f15  [Confession, NationalCandyCornDay, CouldEatThe...   \n",
       "0x1c7f16                                                 []   \n",
       "...                                                     ...   \n",
       "0x38fe18                                                 []   \n",
       "0x38fe19                     [WesHoolahan, WALvIRL, COYBIG]   \n",
       "0x38fe1a                                        [not, maga]   \n",
       "0x38fe1c                                                 []   \n",
       "0x38fe1d                     [redheadproblems, ouch, burnt]   \n",
       "\n",
       "                                                       text  _score  \\\n",
       "tweet_id                                                              \n",
       "0x1c7f10   o m g Shut Up And Dance though #BlackMirror <LH>     242   \n",
       "0x1c7f11  On #twitch <LH> on the #Destinybeta #Destiny #...     915   \n",
       "0x1c7f14  A nice sunny wak this morning not many <LH> ar...     939   \n",
       "0x1c7f15  I'm one of those people who love candy corn......     181   \n",
       "0x1c7f16  @metmuseum What are these? They look like some...     970   \n",
       "...                                                     ...     ...   \n",
       "0x38fe18  @LJPBR @FifthHarmony Um  My vote For @FifthHar...     922   \n",
       "0x38fe19     Where is #WesHoolahan?!  #WALvIRL #COYBIG <LH>      77   \n",
       "0x38fe1a  @mattmfm Fake news! <LH> propagated by Tumpkin...      25   \n",
       "0x38fe1c                    ..today was brutal  ..#Hungover     639   \n",
       "0x38fe1d  Love it when I sun burn my forehead!! NOT!! üò´üò±...     630   \n",
       "\n",
       "                   _crawldate  \n",
       "tweet_id                       \n",
       "0x1c7f10  2015-05-16 10:36:47  \n",
       "0x1c7f11  2016-10-15 20:46:37  \n",
       "0x1c7f14  2016-07-04 07:22:56  \n",
       "0x1c7f15  2016-04-16 12:53:40  \n",
       "0x1c7f16  2017-04-22 17:50:28  \n",
       "...                       ...  \n",
       "0x38fe18  2016-12-06 11:10:57  \n",
       "0x38fe19  2015-02-01 18:04:28  \n",
       "0x38fe1a  2016-12-20 17:19:58  \n",
       "0x38fe1c  2016-09-13 06:31:27  \n",
       "0x38fe1d  2016-09-19 14:35:01  \n",
       "\n",
       "[1455563 rows x 4 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 5, 0, ..., 0, 0, 0],\n",
       "       [0, 2, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 7, 0, ..., 0, 0, 0],\n",
       "       [8, 1, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_BOW_features_500.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['!', '#', '$', '%', '&', \"'\", \"''\", \"'d\", \"'ll\", \"'m\"],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names_500 = BOW_500.get_feature_names_out()\n",
    "feature_names_500[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "train_df.sort_index(inplace=True)\n",
    "label_df.sort_index(inplace=True)\n",
    "np.all(train_df.index == label_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape:  (1455563, 500)\n",
      "y_train.shape:  (1455563,)\n"
     ]
    }
   ],
   "source": [
    "x_train = train_data_BOW_features_500\n",
    "# y_train = small_label['emotion']\n",
    "y_train = label_df['emotion']\n",
    "print('X_train.shape: ', x_train.shape)\n",
    "print('y_train.shape: ', y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet_id\n",
       "0x1c7f10             joy\n",
       "0x1c7f11    anticipation\n",
       "0x1c7f14             joy\n",
       "0x1c7f15             joy\n",
       "0x1c7f16         disgust\n",
       "                ...     \n",
       "0x38fe18         sadness\n",
       "0x38fe19    anticipation\n",
       "0x38fe1a        surprise\n",
       "0x38fe1c         disgust\n",
       "0x38fe1d         sadness\n",
       "Name: emotion, Length: 1455563, dtype: object"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DSTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "DT_model = DecisionTreeClassifier(random_state=1)\n",
    "DT_model = DT_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = DT_model.predict(x_train)\n",
    "test_df = pd.read_pickle('data/test_data.pkl')\n",
    "x_test = BOW_500.transform(test_df['text'])\n",
    "y_test_pred = DT_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hashtags</th>\n",
       "      <th>text</th>\n",
       "      <th>_score</th>\n",
       "      <th>_crawldate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0x28cc61</th>\n",
       "      <td>[]</td>\n",
       "      <td>@Habbo I've seen two separate colours of the e...</td>\n",
       "      <td>107</td>\n",
       "      <td>2017-01-17 14:13:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0x2db41f</th>\n",
       "      <td>[]</td>\n",
       "      <td>@FoxNews @KellyannePolls No serious self respe...</td>\n",
       "      <td>728</td>\n",
       "      <td>2015-10-17 06:46:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0x2466f6</th>\n",
       "      <td>[womendrivers]</td>\n",
       "      <td>Looking for a new car, and it says 1 lady owne...</td>\n",
       "      <td>491</td>\n",
       "      <td>2016-12-19 03:50:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0x23f9e9</th>\n",
       "      <td>[robbingmembers]</td>\n",
       "      <td>@cineworld ‚Äúonly the brave‚Äù just out and fount...</td>\n",
       "      <td>28</td>\n",
       "      <td>2017-04-09 19:32:19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0x1fb4e1</th>\n",
       "      <td>[]</td>\n",
       "      <td>Felt like total dog üí© going into open gym and ...</td>\n",
       "      <td>925</td>\n",
       "      <td>2016-01-15 11:59:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0x2c4dc2</th>\n",
       "      <td>[kids]</td>\n",
       "      <td>6 year old walks in astounded. Mum! Look how b...</td>\n",
       "      <td>792</td>\n",
       "      <td>2017-04-01 02:52:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0x31be7c</th>\n",
       "      <td>[inspiringvolunteerawards2017]</td>\n",
       "      <td>Only one week to go until the #inspiringvolunt...</td>\n",
       "      <td>34</td>\n",
       "      <td>2016-11-13 07:34:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0x1ca58e</th>\n",
       "      <td>[]</td>\n",
       "      <td>I just got caught up with the manga for \"My He...</td>\n",
       "      <td>976</td>\n",
       "      <td>2017-10-26 19:12:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0x35c8ba</th>\n",
       "      <td>[]</td>\n",
       "      <td>Speak only when spoken to and make hot ass mus...</td>\n",
       "      <td>534</td>\n",
       "      <td>2017-08-18 10:23:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0x1d941b</th>\n",
       "      <td>[]</td>\n",
       "      <td>Know what you want and go for it. Fuck everyon...</td>\n",
       "      <td>798</td>\n",
       "      <td>2015-10-02 13:40:35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>411972 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                hashtags  \\\n",
       "tweet_id                                   \n",
       "0x28cc61                              []   \n",
       "0x2db41f                              []   \n",
       "0x2466f6                  [womendrivers]   \n",
       "0x23f9e9                [robbingmembers]   \n",
       "0x1fb4e1                              []   \n",
       "...                                  ...   \n",
       "0x2c4dc2                          [kids]   \n",
       "0x31be7c  [inspiringvolunteerawards2017]   \n",
       "0x1ca58e                              []   \n",
       "0x35c8ba                              []   \n",
       "0x1d941b                              []   \n",
       "\n",
       "                                                       text  _score  \\\n",
       "tweet_id                                                              \n",
       "0x28cc61  @Habbo I've seen two separate colours of the e...     107   \n",
       "0x2db41f  @FoxNews @KellyannePolls No serious self respe...     728   \n",
       "0x2466f6  Looking for a new car, and it says 1 lady owne...     491   \n",
       "0x23f9e9  @cineworld ‚Äúonly the brave‚Äù just out and fount...      28   \n",
       "0x1fb4e1  Felt like total dog üí© going into open gym and ...     925   \n",
       "...                                                     ...     ...   \n",
       "0x2c4dc2  6 year old walks in astounded. Mum! Look how b...     792   \n",
       "0x31be7c  Only one week to go until the #inspiringvolunt...      34   \n",
       "0x1ca58e  I just got caught up with the manga for \"My He...     976   \n",
       "0x35c8ba  Speak only when spoken to and make hot ass mus...     534   \n",
       "0x1d941b  Know what you want and go for it. Fuck everyon...     798   \n",
       "\n",
       "                   _crawldate  \n",
       "tweet_id                       \n",
       "0x28cc61  2017-01-17 14:13:32  \n",
       "0x2db41f  2015-10-17 06:46:20  \n",
       "0x2466f6  2016-12-19 03:50:27  \n",
       "0x23f9e9  2017-04-09 19:32:19  \n",
       "0x1fb4e1  2016-01-15 11:59:31  \n",
       "...                       ...  \n",
       "0x2c4dc2  2017-04-01 02:52:58  \n",
       "0x31be7c  2016-11-13 07:34:17  \n",
       "0x1ca58e  2017-10-26 19:12:59  \n",
       "0x35c8ba  2017-08-18 10:23:59  \n",
       "0x1d941b  2015-10-02 13:40:35  \n",
       "\n",
       "[411972 rows x 4 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv('data/test_data_colab.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = pd.DataFrame(y_test_pred, columns=['emotion'])\n",
    "y_test_pred.set_index(test_df.index, inplace=True)\n",
    "y_test_pred['id'] = y_test_pred.index\n",
    "y_test_pred = y_test_pred[['id', 'emotion']]\n",
    "y_test_pred.to_csv('DT_pred.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99225"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "acc_train = accuracy_score(y_true=y_train, y_pred=y_train_pred)\n",
    "acc_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check label:  ['anger' 'anticipation' 'disgust' 'fear' 'joy' 'sadness' 'surprise'\n",
      " 'trust']\n",
      "\n",
      "## Before convert\n",
      "y_train[0:4]:\n",
      " tweet_id\n",
      "0x1c7f10             joy\n",
      "0x1c7f11    anticipation\n",
      "0x1c7f14             joy\n",
      "0x1c7f15             joy\n",
      "Name: emotion, dtype: object\n",
      "\n",
      "y_train.shape:  (1455563,)\n",
      "\n",
      "\n",
      "## After convert\n",
      "y_train[0:4]:\n",
      " [[0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0.]]\n",
      "\n",
      "y_train.shape:  (1455563, 8)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "print('check label: ', label_encoder.classes_)\n",
    "print('\\n## Before convert')\n",
    "print('y_train[0:4]:\\n', y_train[0:4])\n",
    "print('\\ny_train.shape: ', y_train.shape)\n",
    "\n",
    "\n",
    "import keras\n",
    "def label_encode(le, labels):\n",
    "    enc = le.transform(labels)\n",
    "    return keras.utils.to_categorical(enc)\n",
    "\n",
    "def label_decode(le, one_hot_label):\n",
    "    dec = np.argmax(one_hot_label, axis=1)\n",
    "    return le.inverse_transform(dec)\n",
    "\n",
    "y_train = label_encode(label_encoder, y_train)\n",
    "\n",
    "print('\\n\\n## After convert')\n",
    "print('y_train[0:4]:\\n', y_train[0:4])\n",
    "print('\\ny_train.shape: ', y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_shape:  500\n",
      "output_shape:  8\n"
     ]
    }
   ],
   "source": [
    "input_shape = x_train.shape[1]\n",
    "print('input_shape: ', input_shape)\n",
    "\n",
    "output_shape = len(label_encoder.classes_)\n",
    "print('output_shape: ', output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 500)]             0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 64)                32064     \n",
      "                                                                 \n",
      " re_lu_9 (ReLU)              (None, 64)                0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " re_lu_10 (ReLU)             (None, 64)                0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 8)                 520       \n",
      "                                                                 \n",
      " softmax_3 (Softmax)         (None, 8)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 36,744\n",
      "Trainable params: 36,744\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense\n",
    "from keras.layers import ReLU, Softmax, BatchNormalization \n",
    "\n",
    "# input layer\n",
    "model_input = Input(shape=(input_shape, ))  # 500\n",
    "X = model_input\n",
    "\n",
    "# 1st hidden layer\n",
    "X_W1 = Dense(units=64)(X)  # 64\n",
    "H1 = ReLU()(X_W1)\n",
    "# H1=BatchNormalization()(H1)\n",
    "\n",
    "# 2nd hidden layer\n",
    "H1_W2 = Dense(units=64)(H1)  # 64\n",
    "H2 = ReLU()(H1_W2)\n",
    "# H2=BatchNormalization()(H2)\n",
    "\n",
    "# output layer\n",
    "H2_W3 = Dense(units=output_shape)(H2)  # 8\n",
    "H3 = Softmax()(H2_W3)\n",
    "\n",
    "model_output = H3\n",
    "\n",
    "# create model\n",
    "model = Model(inputs=[model_input], outputs=[model_output])\n",
    "\n",
    "# loss function & optimizer\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# show model construction\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\lab1\\lib\\site-packages\\tensorflow\\python\\framework\\indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_3/dense_12/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_3/dense_12/embedding_lookup_sparse/Reshape:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_3/dense_12/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 3792/45487 [=>............................] - ETA: 11:43 - loss: 1.5137 - accuracy: 0.4484"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [83]\u001b[0m, in \u001b[0;36m<cell line: 10>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m32\u001b[39m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# training!\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcsv_logger\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraining finish\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\lab1\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\lab1\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\lab1\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\lab1\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\lab1\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\lab1\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\lab1\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\lab1\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\lab1\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.callbacks import CSVLogger\n",
    "\n",
    "csv_logger = CSVLogger('logs/training_log.csv')\n",
    "\n",
    "# training setting\n",
    "epochs = 50\n",
    "batch_size = 32\n",
    "\n",
    "# training!\n",
    "history = model.fit(x_train, y_train, \n",
    "                    epochs=epochs, \n",
    "                    batch_size=batch_size, \n",
    "                    callbacks=[csv_logger])\n",
    "print('training finish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12875/12875 [==============================] - 22s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['fear', 'joy', 'trust', ..., 'fear', 'sadness', 'trust'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred = model.predict(x_test, batch_size=32)\n",
    "y_test_pred = label_decode(label_encoder, y_test_pred)\n",
    "y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = pd.DataFrame(y_test_pred, columns=['emotion'])\n",
    "y_test_pred.set_index(test_df.index, inplace=True)\n",
    "y_test_pred['id'] = y_test_pred.index\n",
    "y_test_pred = y_test_pred[['id', 'emotion']]\n",
    "y_test_pred.to_csv('DNN_pred.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attetion model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The DM_Kaggle_att.ipynb in this repository"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I use three different methods to predict.\n",
    "1. Decision Tree: I use Bag-Of-Word for size 500 to get embedding data. Because the training dataset is too huge that the model generate time is too long, I sample 4000 data to speed up the excution time. The result is quite bad, which is about 0.18\n",
    "2. DNN : I try to change the layer structure, but the best result is only 0.21\n",
    "3. Attention model: I get rid of some unimportant word or number or symbol in text, then using Tokenizer with num_words=10000 to embedding those text to length 15 array. I try to implement Attention model and the result 0.42 is much better than previous two methods."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
